---
layout: page
title: Kernel trick
---

These questions refer to slide deck "1.10 Kernel trick". 

Write your answers in a PDF and upload the document on [gradescope](https://www.gradescope.com/courses/102338) for submission.

Each question is worth 10 points. The due date is given on [gradescope](https://www.gradescope.com/courses/102338). Post on [Slack](https://stanford.enterprise.slack.com/) for questions.

Late day policy: 1 late day with a 20% grade penalty.

1. What is the motivation for using kernels in SVM, as opposed to using raw data coordinates directly? 
1. Provide some definition of $$\phi(x)$$ that is non-linear. Describe the family of decision curves that can be described using SVM with $$\phi(x)$$.
1. Explain why the dimension of $$\phi(x)$$ needs to be increased to describe "complicated" decision curves.
1. Assuming we are not using soft-margins, what are the possible values of $$\sum_i \alpha_i K(x^{(i)},x) + b$$ when $$x$$ is a support vector?
1. Explain the role of $$\gamma$$ in the RBF kernel.
1. Describe an example case where an RBF kernel will perform better than a linear kernel.
