---
layout: slides
---

class: center, middle

# CME 216, ME 343 - Winter 2021

## Eric Darve, ICME

![:width 40%](../Stanford.jpg)

---
class: middle

# Physics-informed machine learning

.center[![:width 60%](phys_learning.png)]

---
class: middle

Physics-informed learning leverages:

- Data from experiments and/or high-fidelity computer simulations
- Physics knowledge in the form of constraints

---
class: middle

# Examples of constraints

Equality:

$$F = m a$$

$$ \frac{d \rho}{dt} = 0 $$

$$ \frac{dE}{dt} = 0 $$

---
class: middle

Differential equations:

$$ - \nabla ( k \cdot \nabla u ) = f $$

$$ \nabla \times E = - \frac{\partial B}{\partial t} $$

---
class: middle

$$ - \nabla ( k \cdot \nabla u ) = f $$

Assume we are given $k$ and $f$ and want to compute $u$.

---
class: middle

We may be given some data: $\\{ u(x_i) \\}_i$.

Conventional ML; DNN model $u(x; \theta)$:

$$ \text{Loss} = \sum\_{i=1}^{n\_\text{obs}} \Vert u(x_i; \theta) - u_i \Vert_2^2 $$

---
class: middle

How can we leverage our PDE?

$$ - \nabla ( k \cdot \nabla u ) = f $$

---
class: middle

Add a penalty term:

$$ \hspace{-8em} \text{Loss} = \sum\_{i=1}^{n\_\text{obs}} (u(x\_i; \theta) - u\_i )^2 $$

$$ \hspace{3em} + \lambda \sum\_{j=1}^{n\_\text{phys}} \Big[ f(x_j) + \nabla ( k \cdot \nabla u(x_j;\theta) ) \Big]^2 $$

---
class: middle

A simple idea but with some interesting consequences.

If you have limited observation data $u_i$, the PDE can be used to impose additional constraint on the model $u(x;\theta)$.

This leads to more robust training and more accurate DNN models.

---
class: middle

The model can easily incorporate data measured at irregular locations ($x$) or even time $t$.

---
class: middle

Initial conditions and boundary conditions are less relevant.

With this method you can find approximate solutions of

$$ - \nabla ( k \cdot \nabla u ) = f $$

if you are given enough observations $u_i = u(x_i)$ even **without boundary conditions.**

---
class: middle

This is much harder to do with a traditional scheme like finite-difference where boundary conditions are expected.

---
class: middle

How would we solve

$$ - \nabla ( k \cdot \nabla u ) = f $$

using a convention numerical solver?

---
class: middle

In general, numerical solvers rely on a grid or a discretization of the domain using a mesh.

Take for example:

$$ - \frac{d^2 u}{dx^2} = f(x), \quad u(0) = u_0, \quad u(1) = u_1 $$

---
class: middle

Approximate the 2nd order derivative using the finite-difference scheme:

$$ - \frac{d^2 u}{dx^2} \approx \frac{2u\_i - u\_{i+1} - u\_i}{h^2} $$

$u_i$ is an approximation of $u$ at $x_i = ih$. 

$h$ is the grid size.

---
class: middle

Then, given $f_i$, solve for $u_i$

$$ \frac{2u\_i - u\_{i+1} - u\_i}{h^2} = f\_i $$

This is a linear system.

---
class: middle

PhysML uses a different approach.

It relies on the fact the DNNs can be easily differentiated.

---
class: middle

We have already seen this with the backpropagation algorithm.

This allowed computing

$$ \frac{\partial L}{\partial W_{ij}} $$

efficiently.

---
class: middle

But TensorFlow (PyTorch as well) offers much more general capabilities to compute derivatives.

---
class: middle

In fact it can differentiate any function using **automatic differentiation.**

---
class: middle

$$ y(x) = 4x + x^3 $$

Let's compute $dy/dx$ using automatic differentiation in TensorFlow.

---
class: middle

Declare that $x$ is an independent variable:

```python
x = tf.Variable(1.0)
```

---
class: middle

Define the operations that will require differentiation:

```python
with tf.GradientTape() as g:
    y = 4*x + x**3
```

---
class: middle

Differentiate!

```python
dy_dx = g.gradient(y, x)
print('dy/dx = ', dy_dx)
```

```python
Output: dy/dx =  tf.Tensor(7.0, shape=(), dtype=float32)
```

---
class: middle

We can differentiate with respect to multiple variables.

Take

$y = x_1 + x_2^2$, $x_1 = 1$, $x_2 = 2$

---
class: middle

 Compute:

$$\frac{\partial y}{\partial x_1} = 1$$

$$\frac{\partial y}{\partial x_2} = 2 x_2 = 4$$

---
class: middle

```Python
x1 = tf.Variable(1.0)
x2 = tf.Variable(2.0)

with tf.GradientTape() as g:
    y = x1 + x2**2
    
dy_dx1, dy_dx2 = g.gradient(y, [x1,x2])
print('dy/dx1 = ', dy_dx1.numpy(), '; dy/dx2 = ', dy_dx2.numpy())

Output: dy/dx1 =  1.0 ; dy/dx2 =  4.0
```

---
class: middle

`dy_dx1.numpy()` prints the numerical content of the tensor as a `numpy` variable.

---
class: middle

It's important to distinguish between `tf.Variable` and constant values which are not independent variables.

---
class: middle

```Python
# Standard trainable variable
x0 = tf.Variable(2.0, name='x0')
# A tf.constant is not a variable
c1 = tf.constant(-2.0, name='c1')
# Not trainable because we specify trainable=False
c2 = tf.Variable(-1.0, name='c2', trainable=False)
# variable + tensor returns a tensor. So c3 is not a tf.Variable.
c3 = tf.Variable(1.0, name='c3') + 1.0
# A variable but not used to compute y
x4 = tf.Variable(0., name='x4')
```

---
class: middle

When you differentiate with respect to a constant rather than a `tf.Variable`, TF returns `None`.

```Python
with tf.GradientTape() as g:
    z = x0 + c1
    y = z**2 + (c2**3) + 4*c3

grad = g.gradient(y, [x0, c1, c2, c3, x4])

for dy_dxi in grad:
    print(dy_dxi)
```

---
class: middle

Output

```Python
tf.Tensor(8.0, shape=(), dtype=float32)
None
None
None
None
```

---
class: middle

In some cases, you need TF to interpret a `tf.Tensor` as an independent variable.

---
class: middle

Consider

```Python
x = tf.constant(-3.)

with tf.GradientTape() as g:
    y = tf.math.reduce_sum(x**4)

print(g.gradient(y, x))
```

---
class: middle

What is the output?

--

```Python
None
```

---
class: middle

Instead use `watch`:

```Python
x = tf.constant(-3.)

with tf.GradientTape() as g:
    g.watch(x)
    y = tf.math.reduce_sum(x**4)

print(g.gradient(y, x))  # 4x^3 = 4 27 = 108

Out: tf.Tensor(-108.0, shape=(), dtype=float32)
```

---
class: middle

Tensor of variables can be used as input.

```Python
x = tf.Variable([1, -3.0])
with tf.GradientTape() as g:
    y = tf.math.reduce_sum(x**2)
```

--

See [tf.math](https://www.tensorflow.org/api_docs/python/tf/math) for all tensor operations supported by TF. For example, `tf.math.reduce_sum`.

---
class: middle

In that case, you compute the gradient with respect to each variable in the tensor.

---
class: middle

```Python
print(x.numpy())
print(y.numpy()) # x[0]**2 + x[1]**2 = 1 + 9 = 10
print(g.gradient(y, x))  # (2x[0], 2x[1]) = (2,-6)
Out:
[ 1. -3.]
10.0
tf.Tensor([ 2. -6.], shape=(2,), dtype=float32)
```

---
class: middle

As an extension, when the dependent variable (or target) is a vector, `gradient` returns the sum of the gradients for each component.

---
class: middle

```Python
x = tf.Variable(-1.)
with tf.GradientTape() as g:
    y = [2*x,x**4]

print([y[i].numpy() for i in range(2)]) # [2,1]
print(g.gradient(y, x))  # 2 + 4x^3 = 2 - 4 = -2
Out:
[-2.0, 1.0]
tf.Tensor(-2.0, shape=(), dtype=float32)
```

---
class: middle

Let's consider a more complicated example where we want to differentiate two different functions.

Moreover the input will be a vector of `tf.Variable`.

---
class: middle

```Python
x = tf.Variable([1, -3.0])
with tf.GradientTape() as g:
    y = 2*x
    z = y**2

print(x.numpy())
print(y.numpy())
print(g.gradient(y, x))
print(g.gradient(z, x))
```

---
class: middle

Fail!

--

After calling `gradient`, the resources for `g` are deleted. 

`GradientTape` is not persistent.

---
class: middle

We need to explicitly tell TF not to free the resources.

---
class: middle

```Python
x = tf.Variable([1, -3.0])
with tf.GradientTape(persistent=True) as g:
    y = 2*x
    z = y**2

print(x.numpy())
print(y.numpy())
print(g.gradient(y, x))
print(g.gradient(z, x))
del g # release resources
```

---
class: middle

# What should the output be?

--

`y=2*x`: a tensor of size 2.

`y[0] = 2*x[0]; y[1] = 2*x[1];`

`g.gradient(y, x)`: 

Gradient of `y[0]`: `[2. 0.]`

Gradient of `y[1]`: `[0. 2.]`

---
class: middle

Because `y` is a tensor, you have to sum the gradient of `y[0]` and `y[1]`.

```Python
Out: tf.Tensor([2. 2.], shape=(2,), dtype=float32)
```

---
class: middle

# What is `g.gradient(z, x)`?

--

`z[0]=4*x[0]**2; z[1]=4*x[1]**2` &ensp; with <br/>
`x = tf.Variable([1, -3.0])`

`g.gradient(z, x)`: `[8*x[0] + 0., 0. + 8*x[1]]`<br/>
which is `[8., -24]`

```Python
Out: tf.Tensor([  8. -24.], shape=(2,), dtype=float32)
```

---
class: middle

Plotting the derivative is very easy!

---
class: middle

```Python
x = tf.linspace(-10.0, 10.0, 129) # A tf.Tensor, not a tf.Variable

with tf.GradientTape() as g:
    g.watch(x)
    y = tf.math.tanh(x)

dy_dx = g.gradient(y, x)
```

---
class: middle

`y` is a vector such that `y[i] = tanh(x[i])`.

When computing the gradient of `y` with respect to `x[i]` we need to differentiate **all the components** of `y` with respect to `x[i]` and **add** these derivatives together.

---
class: middle

Since `y[i] = tanh(x[i])`, the `i` component of `g.gradient(y, x)` is simply $\text{tanh}'(x_i)$.

---
class: middle

```Python
plt.plot(x, y, label='y')
plt.plot(x, dy_dx, label='dy/dx')
```

.center[![:width 40%](autodiff_tanh.png)]

---
class: middle

More information on [Automatic Differentiation](https://www.tensorflow.org/guide/autodiff)

and

[Advanced Automatic Differentiation](https://www.tensorflow.org/guide/advanced_autodiff)

Everything on [Gradient Tape](https://www.tensorflow.org/api_docs/python/tf/GradientTape)

---
class: middle

Let's apply this to differentiating DNNs with respect to their input.

It's very simple now.

---
class: middle

Build a model

```Python
class AD_Model(tf.keras.models.Model):
    def __init__(self):
        super(AD_Model, self).__init__()
        self.dense_1 = layer_1(2)
        self.dense_2 = layer_2(1)        

    # Forward pass
    def call(self, inputs):
        x = self.dense_1(inputs)        
        y = self.dense_2(x)
        return y

model = AD_Model()
model.build((1,1))        
```

---
class: middle

Differentiate

```Python
x = reshape_2d( tf.linspace(-2.0, 2.0, 129) )

with tf.GradientTape() as g:
    g.watch(x)    
    y = model(x)
    
dy_dx = g.gradient(y, x)
```

---
class: middle


.center[![:width 60%](pi_model.png)]

---
class: middle

Let's build a simple ODE solver using DNNs

$$ y'' = -4 \cos 2x, \quad y(0) = 1, \quad y'(0) = 0 $$

Exact solution: $\cos 2x$

---
class: middle

Build a model like before and add two functions:

`get_derivatives`

`loss`

---
class: middle

```Python
def get_derivatives(self, x_input):
    x = tf.constant(x_input)
    with tf.GradientTape() as g:
        g.watch(x)
        with tf.GradientTape() as gg:
            gg.watch(x)
            y = self(x)
        y_x = gg.gradient(y,x)
    y_xx = g.gradient(y_x,x)
    return y, y_x, y_xx
```

---
class: middle

Second order derivatives are obtained by calling `gradient` twice. 

Gradients can be nested as many times as needed to compute higher-order derivatives.

---
class: middle

Our loss function is of the type:

$$ \hspace{-5em} L = \sum\_{i=1}^{n\_y} (y(x\_i^y;\theta) - y\_i)^2 $$

$$ \hspace{3em} + \sum\_{i=1}^{n\_f} (y''(x\_i^f;\theta) - f\_i)^2 $$

---
class: middle

```Python
def loss(self, X, Y):
    # data observation loss    
    y = self(X[0]) # y(x)
    # Physics loss        
    _, _, phys = self.get_derivatives(X[1]) # y''(x)
    return self.loss_fun(Y[0], y) + self.loss_fun(Y[1], phys) 
```

```
self.loss_fun = tf.keras.losses.MeanSquaredError()
```

---
class: middle

`X[0]`: $x\_i^y$, location of $y_i$ data

`Y[0]`: $y_i$ data

`X[1]`: $x\_i^f$, location of $f_i = y''_i$ data

`Y[1]`: $f_i = y''_i$ data

---
class: middle

We train using the L-BFGS-B scipy optimizer.

---
class: middle

.center[![:width 70%](piml_loss.png)]


---
class: middle

.center[![:width 70%](piml_solution.png)]

---
class: middle

# Final note

PIML can be very useful to solve PDEs in high-dimension.

---
class: middle

Consider our 1D finite-difference model:

$$ -u''(x) = f(x), \quad x \in [0, 1] $$

$$ u\_i \approx u(x\_i), \quad \frac{2u\_i - u\_{i+1} - u\_i}{h^2} = f\_i $$

If $h = 1/n$, we have $n$ grid points $x_i$.

---
class: middle

Poisson's equation in $\mathbb R^d$:

$$ x = (x^1, \dots, x^d) $$

$$ - \triangle u(x) = f(x), \quad x \in [0, 1]^d $$

In dimension $d$, we need $n^d$ points for our finite-difference scheme.

---
class: middle

This becomes quickly intractable even for moderate values of $d$.

---
class: middle

However, PhysML does not require any grid. 

It can evaluate

$$ - \triangle u(x) $$

directly using automatic differentiation.

---
class: middle

Assuming enough data for $u$ and $f$ are provided it is possible to [solve high-dimensional PDEs](https://www.sciencedirect.com/science/article/pii/S0021999118305527).

---
class: middle

A famous example is the [Black-Scholes equation](https://www.sciencedirect.com/science/article/pii/S0021999118305527):

$$\hspace{-8em} 0 = \frac{\partial u}{\partial t} + \mu(x) \frac{\partial u}{\partial x} + $$

$$\hspace{2em} + \frac{1}{2} \sum\_{i,j=1}^d \rho\_{ij} \sigma(x\_i) \sigma(x\_j) \frac{\partial^2 u}{\partial x\_i \partial x\_j} - r u(t,x) $$

$$x \in \mathbb R^d$$

---
class: middle

Black-Scholes is a mathematical model for the dynamics of a financial market containing derivative investment instruments.

Derivative: a contract that derives its value from the performance of an underlying entity. Examples of underlying entities: asset, index, and interest rate.

---
class: middle

Black-Scholes gives a theoretical estimate of the price of European-style options .

The key idea behind the model is to hedge the option by buying and selling the underlying asset in just the right way and, as a consequence, to eliminate risk.

---
class: middle

Other [examples](https://www.pnas.org/content/115/34/8505.short) of high-dimensional PDEs include:

- Hamilton–Jacobi–Bellman equation
- Allen–Cahn equation